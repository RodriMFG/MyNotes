{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d1ed9e7",
   "metadata": {},
   "source": [
    "## PyTorch: Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07afec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe980d9e",
   "metadata": {},
   "source": [
    "### Numpy vs Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e7d585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.  , 0.25, 0.5 , 0.75, 1.  ]),\n",
       " tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.linspace(0,1,5)\n",
    "t = torch.linspace(0,1,5)\n",
    "n, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a894ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       " \n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]],\n",
       " \n",
       "        [[24, 25, 26, 27],\n",
       "         [28, 29, 30, 31],\n",
       "         [32, 33, 34, 35]]]),\n",
       " tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]],\n",
       " \n",
       "         [[12, 13, 14, 15],\n",
       "          [16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]],\n",
       " \n",
       "         [[24, 25, 26, 27],\n",
       "          [28, 29, 30, 31],\n",
       "          [32, 33, 34, 35]]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.arange(36).reshape(3,3,4)\n",
    "t = torch.arange(36).reshape(3,3,4)\n",
    "n, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ff9f92",
   "metadata": {},
   "source": [
    "### Broadcasting Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927d4d5",
   "metadata": {},
   "source": [
    "When operating on two arrays, NumPy operates element-wise from the right. Two dimensions are compatible whe they're equal or one of them is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a925426f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.]]),\n",
       " array([[0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((6, 5)) #dim(a) = (6, 5)\n",
    "b = np.arange(5).reshape((1, 5)) #dim(b) = (1, 5)\n",
    "a + b, a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1457b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scale = torch.tensor([0.5, 1.5 , 1])\n",
    "Image = torch.randn((256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5a46dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1634,  2.1713, -1.1292],\n",
       "         [-0.2007, -1.0559,  0.8080],\n",
       "         [ 0.7907,  1.8973, -0.7830],\n",
       "         ...,\n",
       "         [ 1.0116, -0.0690, -0.5089],\n",
       "         [ 0.3779,  1.1526, -0.6225],\n",
       "         [ 0.1728, -0.5644,  0.9306]],\n",
       "\n",
       "        [[-0.0120,  0.3001,  1.2713],\n",
       "         [ 0.5120, -1.8691,  0.8941],\n",
       "         [-0.2204,  1.2343, -0.7813],\n",
       "         ...,\n",
       "         [ 0.0714,  0.8257, -0.9739],\n",
       "         [-0.3518, -0.8055, -0.1430],\n",
       "         [-0.0250,  3.7371,  0.6299]],\n",
       "\n",
       "        [[-0.4548, -2.0558,  0.2939],\n",
       "         [-0.4581, -0.5241, -1.2545],\n",
       "         [ 0.3052, -1.6021, -0.9727],\n",
       "         ...,\n",
       "         [ 0.2978,  0.4803,  0.0106],\n",
       "         [-0.1763, -1.8088, -0.2131],\n",
       "         [-0.2420, -0.6122,  0.1082]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3952, -0.0584,  0.4809],\n",
       "         [-0.2726, -1.8083,  0.5468],\n",
       "         [ 0.1329,  0.0296, -0.7861],\n",
       "         ...,\n",
       "         [ 1.1135,  0.5136, -0.6425],\n",
       "         [ 0.1099, -0.8317, -0.9727],\n",
       "         [ 0.1619, -0.8250, -1.1187]],\n",
       "\n",
       "        [[-0.2323, -2.5431, -0.7466],\n",
       "         [ 0.2315,  1.7469, -1.0739],\n",
       "         [ 0.3471, -0.7657, -1.4681],\n",
       "         ...,\n",
       "         [-0.2612,  1.5854, -0.8267],\n",
       "         [ 0.1407, -1.2999,  0.2864],\n",
       "         [-0.5031, -0.8266,  0.3963]],\n",
       "\n",
       "        [[-1.0786, -0.7055, -1.4049],\n",
       "         [ 0.7265, -0.1721,  1.3166],\n",
       "         [ 0.2358, -1.8259, -0.0666],\n",
       "         ...,\n",
       "         [ 0.2198,  1.3667, -0.6860],\n",
       "         [-0.4194, -1.7837, -0.1490],\n",
       "         [ 0.2691, -0.4570, -0.8273]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image*Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "303f6e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image = torch.randn((2, 256, 256, 3))\n",
    "Scale = torch.tensor([0.5, 1.5, 1, 1.5, 1, 0.5]).reshape((2, 1, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "376ea208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.6629e-01, -6.9128e-01, -5.0191e-01],\n",
       "          [-3.1175e-02, -1.3800e-01, -6.1359e-01],\n",
       "          [ 9.4043e-02, -2.0676e-01,  7.0954e-01],\n",
       "          ...,\n",
       "          [ 1.9291e-01,  1.9714e+00, -7.9921e-01],\n",
       "          [-1.1566e-01,  4.1141e-01, -9.9923e-02],\n",
       "          [ 8.6408e-02, -1.9453e-01,  1.7568e+00]],\n",
       "\n",
       "         [[-4.6344e-01,  2.6441e-02, -1.0039e-01],\n",
       "          [ 1.8243e-01,  5.0761e-02,  1.3067e+00],\n",
       "          [ 3.4766e-01, -3.8414e-01,  7.2780e-01],\n",
       "          ...,\n",
       "          [ 3.0570e-01,  3.0132e+00,  8.2712e-01],\n",
       "          [-8.7221e-01, -1.3217e-01,  4.1263e-01],\n",
       "          [ 3.0316e-01, -1.2320e+00,  1.8330e+00]],\n",
       "\n",
       "         [[ 3.9512e-01, -1.7645e+00, -1.9225e+00],\n",
       "          [-1.0295e-01,  3.1303e+00,  9.6039e-01],\n",
       "          [-7.9477e-01,  4.1056e+00, -3.4458e-01],\n",
       "          ...,\n",
       "          [ 8.6349e-02, -3.5881e-01,  1.8503e+00],\n",
       "          [ 8.6052e-01, -1.7572e+00, -1.8108e-01],\n",
       "          [-1.6112e-01, -2.0554e+00,  1.0546e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.6227e-01, -1.5558e+00, -7.0861e-01],\n",
       "          [-2.0257e-01, -5.8095e-01, -3.7314e-01],\n",
       "          [ 8.8009e-01,  5.7099e-01,  9.8007e-01],\n",
       "          ...,\n",
       "          [ 1.7525e-01,  1.0567e-01, -6.9375e-01],\n",
       "          [-1.4954e-01,  1.7037e+00,  7.7052e-01],\n",
       "          [ 4.0941e-01,  5.7413e-01, -3.8398e-01]],\n",
       "\n",
       "         [[ 5.1509e-02, -4.6649e-01,  1.5158e-01],\n",
       "          [-5.6516e-02, -1.9521e+00, -1.6420e+00],\n",
       "          [ 3.7882e-02,  1.0582e+00,  1.7057e+00],\n",
       "          ...,\n",
       "          [-1.1718e+00,  4.9773e-01,  2.8296e-02],\n",
       "          [ 3.8288e-01, -2.3443e+00,  7.6338e-01],\n",
       "          [-3.5453e-01,  2.5421e-01,  8.0148e-01]],\n",
       "\n",
       "         [[-7.1962e-01,  1.1776e+00,  9.3691e-01],\n",
       "          [-6.6053e-02,  6.6960e-01, -1.3507e-01],\n",
       "          [-5.5275e-01, -3.3532e-01, -5.2040e-02],\n",
       "          ...,\n",
       "          [-9.0113e-01,  4.0691e-01,  9.0326e-01],\n",
       "          [ 4.8905e-01,  6.3717e-01, -1.2042e+00],\n",
       "          [ 9.1821e-01,  1.9930e+00,  1.1788e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.5485e-01, -1.0222e+00,  9.9333e-01],\n",
       "          [-2.5203e+00,  4.2634e-01,  7.9029e-01],\n",
       "          [ 9.1925e-01, -1.0572e+00, -1.4591e-01],\n",
       "          ...,\n",
       "          [-2.2932e-02,  1.1867e+00, -2.2033e-01],\n",
       "          [-3.9139e-01, -2.5758e+00, -5.7921e-01],\n",
       "          [-1.9629e-01, -1.3160e+00,  3.4075e-01]],\n",
       "\n",
       "         [[ 6.5345e-01,  6.3145e-01,  3.5041e-03],\n",
       "          [-4.3099e+00,  5.4871e-01, -1.0559e+00],\n",
       "          [-2.2497e+00, -1.7051e+00,  5.4547e-01],\n",
       "          ...,\n",
       "          [ 1.6607e+00,  5.8476e-01,  4.3320e-01],\n",
       "          [ 1.8564e+00, -1.2824e-01,  3.1073e-01],\n",
       "          [-1.2382e+00, -5.2736e-01, -3.7579e-01]],\n",
       "\n",
       "         [[ 3.0750e-02, -1.7320e+00, -7.9067e-01],\n",
       "          [-1.4295e+00, -2.4058e-01, -9.1515e-01],\n",
       "          [ 1.9738e-01, -8.6752e-01,  2.0135e-01],\n",
       "          ...,\n",
       "          [-1.0162e+00,  4.0949e-01,  3.9501e-01],\n",
       "          [-3.1570e+00,  1.1753e+00, -3.6082e-01],\n",
       "          [-1.4378e+00, -2.4776e+00, -2.2240e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.5484e+00, -4.8416e-01, -4.1581e-01],\n",
       "          [ 2.7288e+00, -8.0995e-01, -1.1410e-01],\n",
       "          [ 1.2237e-01,  5.3321e-01,  4.5625e-01],\n",
       "          ...,\n",
       "          [-1.2181e+00, -1.5941e+00, -4.3001e-01],\n",
       "          [ 9.8231e-01, -1.0308e-01, -7.1539e-01],\n",
       "          [ 1.9597e+00, -8.1926e-01, -5.5998e-01]],\n",
       "\n",
       "         [[-3.9861e-01,  7.1206e-02,  2.1776e-01],\n",
       "          [-7.9661e-01,  6.3586e-01,  7.1422e-01],\n",
       "          [-1.7832e+00,  2.3529e-01,  6.5146e-01],\n",
       "          ...,\n",
       "          [-1.0671e+00,  2.6527e-01,  8.5202e-01],\n",
       "          [ 1.9680e-02,  4.1200e-01, -3.1883e-01],\n",
       "          [ 1.9879e+00, -1.6767e-01,  3.2281e-01]],\n",
       "\n",
       "         [[ 1.2517e+00, -6.4061e-01,  3.0176e-01],\n",
       "          [-6.3309e-01, -6.2961e-01, -1.9983e-01],\n",
       "          [-1.2709e+00,  2.7288e-01, -3.3476e-01],\n",
       "          ...,\n",
       "          [ 9.3025e-01, -1.2415e+00,  8.5068e-01],\n",
       "          [-1.5173e+00,  7.8078e-01,  4.1305e-01],\n",
       "          [-2.4425e+00,  2.6021e-01,  2.1558e-01]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image*Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195390e0",
   "metadata": {},
   "source": [
    "### Operations over dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4ed2edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.1250), tensor(1.6520), tensor(4.), tensor(0.5000))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([0.5, 1, 3, 4])\n",
    "torch.mean(t), torch.std(t), torch.max(t), torch.min(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f385e921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]], dtype=torch.float64),\n",
       " tensor([ 8.,  9., 10., 11.], dtype=torch.float64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(20, dtype=float).reshape(5, 4)\n",
    "t, torch.mean(t, axis=0) #mean across the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3172bd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 3.0033,  2.7461, -0.1632],\n",
      "          [ 0.2548,  0.9874, -1.0438],\n",
      "          [-2.2540, -0.3068,  0.0418],\n",
      "          [-1.2261,  0.4125, -0.7121]],\n",
      "\n",
      "         [[-0.1110, -0.6103, -0.1660],\n",
      "          [ 0.5552,  0.0794,  0.1621],\n",
      "          [ 0.1069, -1.1227,  0.3217],\n",
      "          [-0.2307,  0.8903, -0.3795]],\n",
      "\n",
      "         [[ 1.1994,  1.4867, -0.4862],\n",
      "          [ 1.1714,  0.9742, -1.2106],\n",
      "          [ 0.8781,  1.3694,  2.0522],\n",
      "          [ 1.0669,  0.8658,  0.3261]],\n",
      "\n",
      "         [[ 0.7036,  0.1829, -0.4007],\n",
      "          [-0.9376, -0.2886,  1.6389],\n",
      "          [-1.0259, -0.3360,  0.4060],\n",
      "          [-0.2921,  0.9432,  0.4077]]],\n",
      "\n",
      "\n",
      "        [[[-0.8653,  0.8024,  0.7306],\n",
      "          [-1.3010, -0.6427,  0.2586],\n",
      "          [-1.3155,  0.8494,  0.6151],\n",
      "          [-0.3393,  1.2909,  0.7958]],\n",
      "\n",
      "         [[ 0.0095, -0.1855, -0.2000],\n",
      "          [ 1.3177, -0.6248, -0.0692],\n",
      "          [-0.3019,  0.7019,  0.4337],\n",
      "          [-0.3266, -0.3216, -1.5235]],\n",
      "\n",
      "         [[ 0.6664,  1.3566,  0.6241],\n",
      "          [ 0.7033, -0.9434,  0.2518],\n",
      "          [-0.5252, -0.1970,  1.0865],\n",
      "          [-0.0843, -0.8482,  1.7342]],\n",
      "\n",
      "         [[ 0.0195,  0.0206, -0.7725],\n",
      "          [ 0.1098,  2.5815, -0.1050],\n",
      "          [ 0.1584,  1.3871,  1.4025],\n",
      "          [ 0.5641, -0.6649,  0.3376]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(2, 4, 4, 3)\n",
    "#to take the mean across the batch (axis=0)\n",
    "print(t)\n",
    "torch.mean(t, axis=0).shape#, torch.mean(t, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1743e5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8621,  0.0661, -0.8397, -0.5086],\n",
       "         [-0.2958,  0.2656, -0.2314,  0.0934],\n",
       "         [ 0.7333,  0.3117,  1.4332,  0.7529],\n",
       "         [ 0.1619,  0.1375, -0.3186,  0.3529]],\n",
       "\n",
       "        [[ 0.2226, -0.5617,  0.0497,  0.5825],\n",
       "         [-0.1253,  0.2079,  0.2779, -0.7239],\n",
       "         [ 0.8824,  0.0039,  0.1214,  0.2672],\n",
       "         [-0.2441,  0.8621,  0.9827,  0.0789]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take the mean across the color channels\n",
    "torch.mean(t, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7078c4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[[ 3.0033,  0.9874,  0.0418,  0.4125],\n",
       "         [-0.1110,  0.5552,  0.3217,  0.8903],\n",
       "         [ 1.4867,  1.1714,  2.0522,  1.0669],\n",
       "         [ 0.7036,  1.6389,  0.4060,  0.9432]],\n",
       "\n",
       "        [[ 0.8024,  0.2586,  0.8494,  1.2909],\n",
       "         [ 0.0095,  1.3177,  0.7019, -0.3216],\n",
       "         [ 1.3566,  0.7033,  1.0865,  1.7342],\n",
       "         [ 0.0206,  2.5815,  1.4025,  0.5641]]]),\n",
       "indices=tensor([[[0, 1, 2, 1],\n",
       "         [0, 0, 2, 1],\n",
       "         [1, 0, 2, 0],\n",
       "         [0, 2, 2, 1]],\n",
       "\n",
       "        [[1, 2, 1, 1],\n",
       "         [0, 0, 1, 1],\n",
       "         [1, 0, 2, 2],\n",
       "         [1, 1, 2, 0]]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(t, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9525bb2a",
   "metadata": {},
   "source": [
    "### Gradients in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad2d8ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(917., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[5., 8.],[4., 6.]], requires_grad=True)\n",
    "#store gradient after any operations\n",
    "y = x.pow(3).sum() #operation\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26eb0bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 75., 192.],\n",
       "        [ 48., 108.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward() #compute gradient\n",
    "x.grad  #print the gradient (it is stored in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bf62a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 75., 192.],\n",
       "        [ 48., 108.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the result analitically\n",
    "3*x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed0f258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
