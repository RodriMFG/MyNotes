{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3893a21e",
   "metadata": {},
   "source": [
    "## PyTorch: Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac5e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd64199e",
   "metadata": {},
   "source": [
    "Let's consider a data set that consists of a independent vector $x_i$ and a dependant vector $y_i$.  \n",
    "The goal of a neural network is to find a function that can make predictions:  \n",
    "$$\n",
    "\\hat{y_i} = f(x_i; a)\n",
    "$$  \n",
    "Where $a$ is parameter vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a81269",
   "metadata": {},
   "source": [
    "We can define a *Loss* function $L(y, \\hat{y})$, which is inversly proportional to the difference between $y_i$s and $\\hat{y}$s. Example of a simple loss function:  \n",
    "$$\n",
    "L(y, \\hat{y}) = \\sum_i (y_i - \\hat{y_i})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a6265",
   "metadata": {},
   "source": [
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83c43af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[6,2],[5,2],[1,3],[7,6]]).float()\n",
    "y = torch.tensor([1,5,2,5]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb7c30b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2]),\n",
       " tensor([[6., 2.],\n",
       "         [5., 2.],\n",
       "         [1., 3.],\n",
       "         [7., 6.]]),\n",
       " torch.Size([4]),\n",
       " tensor([1., 5., 2., 5.]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x, y.shape, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef7e1e0",
   "metadata": {},
   "source": [
    "We want to predict $y$ using the $x$ tensor:  \n",
    "We have $x_1 = (6,2), x_2 = (5,2), \\dots$  \n",
    "And $y_1 = 1, y_2 = 5, \\dots$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53047d9e",
   "metadata": {},
   "source": [
    "Now let's define the parameter vector $a$, this can be as large as we want it to be.  \n",
    "Let's multiply each vector element ($(6,2)$, etc.) by an $8\\times{2}$ matrix (this is 16 parameter $a_i$).  \n",
    "Now multiply each element in $x$ by a $1\\times{8}$ matrix (this is 8 parameters $a_i$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35881c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=8, bias=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The matrix is initially created with random values\n",
    "#We create the matrix with no bias, i.e. no scalar value for the function\n",
    "M1 = nn.Linear(2, 8, bias = False)\n",
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78a14f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0400,  3.4515,  2.3830,  1.5895,  1.3507,  4.5750,  2.1904,  3.2824],\n",
       "        [-0.7310,  2.7467,  1.9173,  1.5138,  1.3155,  3.9038,  2.0021,  2.8887],\n",
       "        [ 0.9114, -0.4616, -0.1508,  1.7788,  1.7442,  1.4930,  1.7796,  1.7740],\n",
       "        [ 0.2782,  2.6012,  2.0267,  3.9360,  3.6645,  6.3420,  4.5005,  5.5166]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If we pass x, each of it's elements (2d vectors) are multiplied by M1\n",
    "#Giving us a tensor formed by four 8d vectors\n",
    "M1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "275adf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8, out_features=1, bias=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Our second matrix M2\n",
    "M2 = nn.Linear(8, 1, bias = False)\n",
    "M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f87c3157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3737],\n",
       "        [1.2747],\n",
       "        [1.2688],\n",
       "        [3.0324]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2(M1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dee4e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1]), torch.Size([4]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Our result doesn't line up (dimension-wise) to the expected result y\n",
    "M2(M1(x)).shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62987157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4]),\n",
       " tensor([1.3737, 1.2747, 1.2688, 3.0324], grad_fn=<SqueezeBackward0>))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can remove the extra dimension with the function:\n",
    "M2(M1(x)).squeeze().shape, M2(M1(x)).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723013c",
   "metadata": {},
   "source": [
    "We see that our result doesn't match the expected result $y_i$. This is because the parameters haven't been touched (or trained). This is were machine learning comes in to play, where we can train our network in order to optimize the values of M1 and M2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3aed4743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a subclass of nn.Module to store the parameters of a\n",
    "#Later we can adjust these weights\n",
    "\n",
    "class MyNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Matrix1 = nn.Linear(2,8,bias=False)\n",
    "        self.Matrix2 = nn.Linear(8,1,bias=False)\n",
    "    def forward(self,x):\n",
    "        x = self.Matrix1(x)\n",
    "        x = self.Matrix2(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0099b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = MyNeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "465e98df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.6957, -0.2445],\n",
      "        [ 0.3150,  0.5439],\n",
      "        [-0.1474, -0.4681],\n",
      "        [-0.3217,  0.3290],\n",
      "        [-0.1569, -0.4198],\n",
      "        [-0.3657,  0.3634],\n",
      "        [-0.1470,  0.4067],\n",
      "        [ 0.6392, -0.3233]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0838, -0.0183,  0.0029,  0.1806,  0.2983, -0.0258, -0.0474, -0.3128]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for par in f.parameters():\n",
    "    print(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f330e597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 5., 2., 5.]),\n",
       " tensor([-2.1679, -1.8150, -0.4284, -2.6214], grad_fn=<SqueezeBackward0>))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = f(x)\n",
    "y, yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e68b08",
   "metadata": {},
   "source": [
    "#### Adjusting $a$ so that $\\hat{y}$ and $y$ are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32f1e99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.1155, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We'll use a builtin loss function of mean squared error\n",
    "L = nn.MSELoss()\n",
    "L(y, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5b69de",
   "metadata": {},
   "source": [
    "The main idea is to compute the gradient of $L$ in respect to $a$, this is:  \n",
    "We have the loss function (which we want to minimize) $L = L(a)$, we want to find:  \n",
    "$$\n",
    "\\frac{\\partial L}{\\partial a_i}\n",
    "$$  \n",
    "For each parameter $a_i$ we want to adjust it as follows:  \n",
    "$$\n",
    "a_i \\rightarrow a_i - \\ell\\frac{\\partial L}{\\partial a_i}\n",
    "$$  \n",
    "Where $\\ell$ is the learning rate (how fast is $a_i$ adjusted with every training batch. If $\\ell$ is to large we will constantly be \"overshooting\" the local minimum we are looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6671dc59",
   "metadata": {},
   "source": [
    "To do this we can use the SDG function (stochastic gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87a26181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes the parameters and learning rate\n",
    "opt = SGD(f.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04b7e2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can now adjust the parameters over and over\n",
    "losses = []\n",
    "for _ in range(50):\n",
    "    opt.zero_grad() #flush previous gradient\n",
    "    loss_value = L(f(x), y) #compute loss\n",
    "    loss_value.backward() #compute gradient\n",
    "    opt.step() #perform iteration using the gradient\n",
    "    losses.append(loss_value.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5da6f9",
   "metadata": {},
   "source": [
    "Plot Loss function with different iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a337208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "29b5cc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.9119, 2.5870, 1.7690, 5.1622], grad_fn=<SqueezeBackward0>),\n",
       " tensor([1., 5., 2., 5.]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848863c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
