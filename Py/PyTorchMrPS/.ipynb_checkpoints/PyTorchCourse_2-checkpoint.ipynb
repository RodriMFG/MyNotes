{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b33db1",
   "metadata": {},
   "source": [
    "## PyTorch: Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78235b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e29b91",
   "metadata": {},
   "source": [
    "Let's consider a data set that consists of a independent vector $x_i$ and a dependant vector $y_i$.  \n",
    "The goal of a neural network is to find a function that can make predictions:  \n",
    "$$\n",
    "\\hat{y_i} = f(x_i; a)\n",
    "$$  \n",
    "Where $a$ is parameter vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f02da74",
   "metadata": {},
   "source": [
    "We can define a *Loss* function $L(y, \\hat{y})$, which is inversly proportional to the difference between $y_i$s and $\\hat{y}$s. Example of a simple loss function:  \n",
    "$$\n",
    "L(y, \\hat{y}) = \\sum_i (y_i - \\hat{y_i})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20db5a00",
   "metadata": {},
   "source": [
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d1d6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[6,2],[5,2],[1,3],[7,6]]).float()\n",
    "y = torch.tensor([1,5,2,5]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "278db818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2]),\n",
       " tensor([[6., 2.],\n",
       "         [5., 2.],\n",
       "         [1., 3.],\n",
       "         [7., 6.]]),\n",
       " torch.Size([4]),\n",
       " tensor([1., 5., 2., 5.]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x, y.shape, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f1fe3e",
   "metadata": {},
   "source": [
    "We want to predict $y$ using the $x$ tensor:  \n",
    "We have $x_1 = (6,2), x_2 = (5,2), \\dots$  \n",
    "And $y_1 = 1, y_2 = 5, \\dots$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab68bd5",
   "metadata": {},
   "source": [
    "Now let's define the parameter vector $a$, this can be as large as we want it to be.  \n",
    "Let's multiply each vector element ($(6,2)$, etc.) by an $8\\times{2}$ matrix (this is 16 parameter $a_i$).  \n",
    "Now multiply each element in $x$ by a $1\\times{8}$ matrix (this is 8 parameters $a_i$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d75a955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=8, bias=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The matrix is initially created with random values\n",
    "#We create the matrix with no bias, i.e. no scalar value for the function\n",
    "M1 = nn.Linear(2, 8, bias = False)\n",
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de21b701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1207, -2.7310,  1.1480, -2.8647,  2.7543,  1.9357, -2.2801,  2.3892],\n",
       "        [ 1.6493, -2.4681,  1.0796, -2.2498,  2.5084,  1.6316, -1.9016,  1.9220],\n",
       "        [-0.5903, -1.9934,  1.1749,  0.6217,  2.1645,  0.4707, -0.3923, -0.1534],\n",
       "        [ 1.1765, -5.3011,  2.6918, -1.8308,  5.5583,  2.4620, -2.6770,  2.0288]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If we pass x, each of it's elements (2d vectors) are multiplied by M1\n",
    "#Giving us a tensor formed by four 8d vectors\n",
    "M1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d322fc0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8, out_features=1, bias=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Our second matrix M2\n",
    "M2 = nn.Linear(8, 1, bias = False)\n",
    "M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ae2b613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0078],\n",
       "        [2.5247],\n",
       "        [0.6471],\n",
       "        [3.7095]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2(M1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "738f92b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1]), torch.Size([4]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Our result doesn't line up (dimension-wise) to the expected result y\n",
    "M2(M1(x)).shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f16c6ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4]),\n",
       " tensor([3.0078, 2.5247, 0.6471, 3.7095], grad_fn=<SqueezeBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can remove the extra dimension with the function:\n",
    "M2(M1(x)).squeeze().shape, M2(M1(x)).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af4ef5a",
   "metadata": {},
   "source": [
    "We see that our result doesn't match the expected result $y_i$. This is because the parameters haven't been touched (or trained). This is were machine learning comes in to play, where we can train our network in order to optimize the values of M1 and M2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "634c2271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a subclass of nn.Module to store the parameters of a\n",
    "#Later we can adjust these weights\n",
    "\n",
    "class MyNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Matrix1 = nn.Linear(2,8,bias=False)\n",
    "        self.Matrix2 = nn.Linear(8,1,bias=False)\n",
    "    def forward(self,x):\n",
    "        x = self.Matrix1(x)\n",
    "        x = self.Matrix2(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2e13a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = MyNeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "242600b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.6339,  0.1724],\n",
      "        [-0.1755,  0.5212],\n",
      "        [-0.4180,  0.4025],\n",
      "        [ 0.5704,  0.4971],\n",
      "        [ 0.2045, -0.0479],\n",
      "        [ 0.1988, -0.4378],\n",
      "        [ 0.2318,  0.0851],\n",
      "        [-0.5445,  0.2366]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.3045,  0.2638,  0.2369, -0.1356, -0.1990, -0.3007,  0.2599,  0.0503]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for par in f.parameters():\n",
    "    print(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c350962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 5., 2., 5.]),\n",
       " tensor([-2.1132, -1.6299,  0.6962, -1.0238], grad_fn=<SqueezeBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = f(x)\n",
    "y, yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3ba182",
   "metadata": {},
   "source": [
    "#### Adjusting $a$ so that $\\hat{y}$ and $y$ are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e09beb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22.9085, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We'll use a builtin loss function of mean squared error\n",
    "L = nn.MSELoss()\n",
    "L(y, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907d0bdb",
   "metadata": {},
   "source": [
    "The main idea is to compute the gradient of $L$ in respect to $a$, this is:  \n",
    "We have the loss function (which we want to minimize) $L = L(a)$, we want to find:  \n",
    "$$\n",
    "\\frac{\\partial L}{\\partial a_i}\n",
    "$$  \n",
    "For each parameter $a_i$ we want to adjust it as follows:  \n",
    "$$\n",
    "a_i \\rightarrow a_i - \\ell\\frac{\\partial L}{\\partial a_i}\n",
    "$$  \n",
    "Where $\\ell$ is the learning rate (how fast is $a_i$ adjusted with every training batch. If $\\ell$ is to large we will constantly be \"overshooting\" the local minimum we are looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ccc9c9",
   "metadata": {},
   "source": [
    "To do this we can use the SDG function (stochastic gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71ecd33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes the parameters and learning rate\n",
    "opt = SGD(f.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d9b84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can now adjust the parameters over and over\n",
    "losses = []\n",
    "for _ in range(50):\n",
    "    opt.zero_grad() #flush previous gradient\n",
    "    loss_value = L(f(x), y) #compute loss\n",
    "    loss_value.backward() #compute gradient\n",
    "    opt.step() #perform iteration using the gradient\n",
    "    losses.append(loss_value.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9825b112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.908458709716797, 18.680500030517578, 15.403928756713867, 12.818218231201172, 10.753393173217773, 9.092789649963379, 7.752588272094727, 6.670076847076416, 5.796682834625244, 5.09376335144043, 4.529966831207275, 4.079549312591553, 3.721235752105713, 3.437422513961792, 3.2135684490203857, 3.037714958190918, 2.900080442428589, 2.7927188873291016, 2.709214925765991, 2.6444249153137207, 2.594249725341797, 2.555443525314331, 2.5254502296447754, 2.5022668838500977, 2.4843318462371826, 2.470430374145508, 2.4596245288848877, 2.4511890411376953, 2.4445669651031494, 2.4393303394317627, 2.435152053833008, 2.431781768798828, 2.4290289878845215, 2.426748752593994, 2.4248290061950684, 2.423186779022217, 2.421757698059082, 2.4204933643341064, 2.419356346130371, 2.4183197021484375, 2.41736102104187, 2.4164652824401855, 2.4156198501586914, 2.4148144721984863, 2.414044141769409, 2.413301467895508, 2.4125828742980957, 2.4118857383728027, 2.4112067222595215, 2.4105446338653564]\n"
     ]
    }
   ],
   "source": [
    "print(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245b95c5",
   "metadata": {},
   "source": [
    "Plot Loss function with different iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27156138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bed524a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.5641, 2.3571, 2.1897, 5.4148], grad_fn=<SqueezeBackward0>),\n",
       " tensor([1., 5., 2., 5.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618711fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
