{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58d2182f",
   "metadata": {},
   "source": [
    "## PyTorch: Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3311e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2321de1c",
   "metadata": {},
   "source": [
    "### Numpy vs Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b08557a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.  , 0.25, 0.5 , 0.75, 1.  ]),\n",
       " tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.linspace(0,1,5)\n",
    "t = torch.linspace(0,1,5)\n",
    "n, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9877e7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       " \n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]],\n",
       " \n",
       "        [[24, 25, 26, 27],\n",
       "         [28, 29, 30, 31],\n",
       "         [32, 33, 34, 35]]]),\n",
       " tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]],\n",
       " \n",
       "         [[12, 13, 14, 15],\n",
       "          [16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]],\n",
       " \n",
       "         [[24, 25, 26, 27],\n",
       "          [28, 29, 30, 31],\n",
       "          [32, 33, 34, 35]]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.arange(36).reshape(3,3,4)\n",
    "t = torch.arange(36).reshape(3,3,4)\n",
    "n, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34894267",
   "metadata": {},
   "source": [
    "### Broadcasting Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d0095",
   "metadata": {},
   "source": [
    "When operating on two arrays, NumPy operates element-wise from the right. Two dimensions are compatible whe they're equal or one of them is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c42dcbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.]]),\n",
       " array([[0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((6, 5)) #dim(a) = (6, 5)\n",
    "b = np.arange(5).reshape((1, 5)) #dim(b) = (1, 5)\n",
    "a + b, a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "459e0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scale = torch.tensor([0.5, 1.5 , 1])\n",
    "Image = torch.randn((256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "324c6699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4723,  1.2102, -0.2212],\n",
       "         [ 0.4824,  0.2268,  1.1495],\n",
       "         [ 0.1815, -1.0261, -0.7696],\n",
       "         ...,\n",
       "         [ 0.0377,  2.0505, -0.8666],\n",
       "         [-0.8262,  1.0570,  0.4603],\n",
       "         [ 0.5568, -1.5806,  0.6101]],\n",
       "\n",
       "        [[-0.3962,  1.6281,  0.7426],\n",
       "         [ 0.6941, -1.5488,  0.7109],\n",
       "         [ 0.2093,  0.9764,  0.1603],\n",
       "         ...,\n",
       "         [ 0.7652, -0.0732, -1.3968],\n",
       "         [ 0.1575,  2.4115, -1.6127],\n",
       "         [ 0.4721, -0.2235, -1.7165]],\n",
       "\n",
       "        [[-0.3976,  1.1511,  1.8154],\n",
       "         [ 0.6378,  3.3528, -0.5221],\n",
       "         [-0.2960,  0.6845, -1.0804],\n",
       "         ...,\n",
       "         [ 0.5730,  1.2821, -1.2824],\n",
       "         [-0.5878, -1.5107,  0.6672],\n",
       "         [-0.3849,  1.0253,  0.5123]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0386, -0.3773, -0.8129],\n",
       "         [-0.5488,  0.6339, -0.2708],\n",
       "         [ 0.1629,  1.8160, -0.9608],\n",
       "         ...,\n",
       "         [-0.5753,  0.3065,  2.1114],\n",
       "         [ 0.0564, -1.3579,  0.6239],\n",
       "         [-0.6737,  0.4252,  1.9493]],\n",
       "\n",
       "        [[ 0.6823,  3.6604,  0.5387],\n",
       "         [ 0.2666,  0.4604, -0.3995],\n",
       "         [ 0.9305, -2.6647,  0.8603],\n",
       "         ...,\n",
       "         [-0.3202,  1.6403, -0.9814],\n",
       "         [-0.3428,  1.1076, -1.4895],\n",
       "         [-0.0303,  0.9494,  1.2663]],\n",
       "\n",
       "        [[ 0.1034,  1.3081,  1.6188],\n",
       "         [ 0.1436, -1.7869, -1.6359],\n",
       "         [ 0.5958, -0.9028,  0.7808],\n",
       "         ...,\n",
       "         [-0.3785,  0.5182, -0.8632],\n",
       "         [ 0.1817, -0.9474,  0.1122],\n",
       "         [ 0.7433,  1.6180, -0.5772]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image*Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3796fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image = torch.randn((2, 256, 256, 3))\n",
    "Scale = torch.tensor([0.5, 1.5, 1, 1.5, 1, 0.5]).reshape((2, 1, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "128f3f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-5.5266e-01, -1.1341e-01, -5.9199e-01],\n",
       "          [-2.6004e-01,  1.8881e+00, -3.8238e-01],\n",
       "          [ 6.0517e-01,  1.3567e+00,  4.4283e-01],\n",
       "          ...,\n",
       "          [ 3.3154e-01,  3.4529e+00,  6.7397e-01],\n",
       "          [ 3.8929e-01,  1.2301e+00,  8.3848e-01],\n",
       "          [-2.6578e-01, -2.9715e+00,  5.0926e-01]],\n",
       "\n",
       "         [[-4.0897e-01,  1.1053e-01, -1.7034e+00],\n",
       "          [ 6.8034e-01,  6.9337e-02,  1.4287e+00],\n",
       "          [-5.1355e-01, -6.0372e-01, -3.4298e-01],\n",
       "          ...,\n",
       "          [ 2.8510e-01,  2.1504e-01,  5.2758e-01],\n",
       "          [-1.1071e+00, -6.6700e-01,  2.1750e+00],\n",
       "          [-4.0828e-01,  1.9905e+00,  5.3045e-01]],\n",
       "\n",
       "         [[ 1.7071e-01, -5.0627e-01, -2.6816e-01],\n",
       "          [-1.0924e+00, -1.1310e+00,  6.5375e-01],\n",
       "          [-7.2297e-02, -6.8339e-02, -6.3288e-01],\n",
       "          ...,\n",
       "          [-6.2756e-01,  1.9943e+00,  2.3628e+00],\n",
       "          [-6.4162e-01, -2.7962e+00, -7.8822e-01],\n",
       "          [ 1.6607e-02, -8.5625e-01, -1.1037e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.5271e-01, -3.6979e-01, -3.5296e-01],\n",
       "          [-6.5318e-01, -5.2379e-01,  6.9739e-01],\n",
       "          [ 9.4883e-02,  1.0013e+00,  1.1248e+00],\n",
       "          ...,\n",
       "          [-1.0557e+00, -2.0350e+00,  2.6031e-01],\n",
       "          [ 4.3282e-01,  9.6732e-01,  7.2811e-01],\n",
       "          [ 4.8357e-01, -3.0110e+00,  3.4567e-01]],\n",
       "\n",
       "         [[ 1.3661e-01, -6.3301e-02, -1.0072e+00],\n",
       "          [ 2.3772e-01,  1.3007e+00,  2.9745e-01],\n",
       "          [-7.2828e-02, -3.7621e+00,  6.9602e-01],\n",
       "          ...,\n",
       "          [-4.4075e-01,  8.1283e-01, -2.0790e+00],\n",
       "          [-3.6802e-01,  3.9856e-01,  4.1585e-01],\n",
       "          [-3.7542e-01, -2.0857e+00,  6.9436e-02]],\n",
       "\n",
       "         [[-1.9891e-01,  8.5472e-01, -3.2585e-01],\n",
       "          [-2.0523e-01, -1.7676e+00,  1.7109e+00],\n",
       "          [-4.4146e-01, -1.3219e+00, -3.8900e-01],\n",
       "          ...,\n",
       "          [ 3.8122e-01,  1.4600e-01,  1.4207e+00],\n",
       "          [-6.9680e-01,  9.0062e-01,  2.7553e-02],\n",
       "          [ 4.6886e-01,  8.3278e-02, -8.0743e-01]]],\n",
       "\n",
       "\n",
       "        [[[-9.9473e-01,  3.7080e-01, -2.3668e-01],\n",
       "          [-3.1806e+00, -1.3110e+00,  1.0192e-01],\n",
       "          [-8.6404e-01,  1.1575e+00,  4.1709e-01],\n",
       "          ...,\n",
       "          [ 6.3328e-01, -2.2005e-01, -7.5628e-02],\n",
       "          [-3.3803e+00,  1.5962e+00, -7.1022e-01],\n",
       "          [ 3.2330e+00, -1.1164e+00,  1.9874e-01]],\n",
       "\n",
       "         [[-1.3866e+00,  3.7666e-01, -3.0319e-01],\n",
       "          [-1.7072e+00, -8.7671e-02, -4.0908e-01],\n",
       "          [-1.4229e+00, -8.9471e-01,  8.2181e-03],\n",
       "          ...,\n",
       "          [-2.1280e-01,  1.2595e+00,  8.1080e-03],\n",
       "          [ 2.8832e+00,  3.7071e-01, -5.3957e-02],\n",
       "          [ 2.9560e+00,  1.1709e+00,  4.5811e-01]],\n",
       "\n",
       "         [[ 2.0435e-01,  2.1624e-01,  1.1370e-01],\n",
       "          [-8.8876e-01,  2.4894e-01, -1.1730e-01],\n",
       "          [ 4.7737e-01,  2.0805e-01, -2.5348e-01],\n",
       "          ...,\n",
       "          [ 8.1760e-01, -5.2426e-01,  4.8078e-01],\n",
       "          [ 6.1031e-01, -2.5816e-01,  9.9767e-02],\n",
       "          [ 2.2964e+00,  5.2349e-01, -2.5230e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0425e+00,  1.0479e+00, -3.7852e-01],\n",
       "          [ 1.2678e+00, -1.8860e-01,  3.8409e-01],\n",
       "          [ 8.3511e-01, -8.3166e-01,  2.1576e-01],\n",
       "          ...,\n",
       "          [-2.7440e-03,  4.4828e-01, -3.8969e-01],\n",
       "          [-4.4798e-01,  9.7789e-01,  1.1475e-01],\n",
       "          [-1.0816e+00, -2.2400e-01, -4.8040e-01]],\n",
       "\n",
       "         [[ 2.2019e+00,  5.3588e-02, -3.2388e-01],\n",
       "          [-8.2356e-01, -7.9391e-01,  1.1215e-01],\n",
       "          [-8.5001e-02,  4.6213e-01, -1.3178e-01],\n",
       "          ...,\n",
       "          [ 1.7864e+00, -6.1099e-02,  5.6017e-01],\n",
       "          [ 1.7645e+00, -5.0806e-01, -3.5498e-01],\n",
       "          [-1.3409e-01,  1.7136e+00,  8.2648e-02]],\n",
       "\n",
       "         [[-1.4641e+00,  1.5904e+00,  2.2598e-01],\n",
       "          [ 2.6929e-02,  7.2724e-01, -4.2732e-02],\n",
       "          [ 3.9676e-01,  6.2216e-01, -2.1729e-01],\n",
       "          ...,\n",
       "          [-4.2346e-01, -4.7010e-01,  2.6499e-01],\n",
       "          [-1.4109e+00, -8.4679e-01, -5.8371e-01],\n",
       "          [-1.3467e-01,  1.4716e+00, -1.5308e+00]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image*Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b061d",
   "metadata": {},
   "source": [
    "### Operations over dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40519f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.1250), tensor(1.6520), tensor(4.), tensor(0.5000))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([0.5, 1, 3, 4])\n",
    "torch.mean(t), torch.std(t), torch.max(t), torch.min(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23e940ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]], dtype=torch.float64),\n",
       " tensor([ 8.,  9., 10., 11.], dtype=torch.float64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(20, dtype=float).reshape(5, 4)\n",
    "t, torch.mean(t, axis=0) #mean across the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39c66ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.2313, -0.0849,  1.3105],\n",
      "          [-0.8361,  0.5203,  0.5200],\n",
      "          [-0.6780,  2.2456,  0.3086],\n",
      "          [ 0.1895,  1.0465,  2.4597]],\n",
      "\n",
      "         [[ 1.4086,  0.6185, -0.1822],\n",
      "          [-1.1406, -0.5274,  0.8140],\n",
      "          [ 0.4720,  0.7458, -1.8108],\n",
      "          [ 0.4119, -1.8295, -0.8990]],\n",
      "\n",
      "         [[ 1.1240, -0.8124, -0.4306],\n",
      "          [-0.1339, -1.0227, -0.3822],\n",
      "          [-0.3291, -1.6024,  0.3029],\n",
      "          [-1.9876,  1.5491,  0.9042]],\n",
      "\n",
      "         [[-0.5503,  0.8649,  0.1352],\n",
      "          [ 0.0788,  1.0408, -1.1536],\n",
      "          [-0.2904, -1.3763,  0.8726],\n",
      "          [-0.1819, -0.5501,  0.3279]]],\n",
      "\n",
      "\n",
      "        [[[-0.3656, -0.4296, -0.2791],\n",
      "          [-1.0856, -0.2518, -0.6485],\n",
      "          [-0.5344,  0.0735,  1.1651],\n",
      "          [ 1.0075,  0.3236,  0.7135]],\n",
      "\n",
      "         [[ 0.2996,  1.1339,  0.8665],\n",
      "          [ 1.8197, -0.9600,  2.6335],\n",
      "          [-1.7311,  0.5378, -0.6113],\n",
      "          [-0.3089,  0.5703,  0.8907]],\n",
      "\n",
      "         [[ 0.1086, -1.4866,  0.5142],\n",
      "          [ 0.8592, -0.2635, -1.1479],\n",
      "          [ 0.5482,  1.1517, -1.0466],\n",
      "          [ 0.6226,  0.6334, -0.8283]],\n",
      "\n",
      "         [[-0.8245,  1.9366,  0.5328],\n",
      "          [ 1.1280, -0.8022, -2.0424],\n",
      "          [-0.5983, -0.4992, -0.1101],\n",
      "          [ 0.6721, -1.1891, -0.0915]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(2, 4, 4, 3)\n",
    "#to take the mean across the batch (axis=0)\n",
    "print(t)\n",
    "torch.mean(t, axis=0).shape#, torch.mean(t, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90e1f406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1541,  0.6625,  0.0059,  0.6214],\n",
       "         [-0.5243, -0.3526,  0.5353,  0.2340],\n",
       "         [-0.4911, -1.1445,  0.4203, -0.2118],\n",
       "         [ 0.1533, -0.1549, -0.3451,  0.0078]],\n",
       "\n",
       "        [[-0.0293, -0.1162,  0.5420,  0.1018],\n",
       "         [-0.0389,  0.9433, -0.7744,  0.6692],\n",
       "         [ 0.1879,  0.3111, -0.1258, -0.9512],\n",
       "         [ 0.0349,  0.3602, -0.5335,  0.9088]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take the mean across the color channels\n",
    "torch.mean(t, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5a781ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[[ 1.1060,  1.4010,  1.0575,  1.4759],\n",
       "         [ 0.9961,  1.9227,  1.7805,  0.8930],\n",
       "         [ 1.9485,  1.8002,  1.6595,  0.4237],\n",
       "         [ 0.4208,  0.2791, -0.2252,  0.8715]],\n",
       "\n",
       "        [[ 1.7673,  0.8441,  0.4462,  0.5742],\n",
       "         [ 0.4109, -0.3469,  0.3370,  1.2666],\n",
       "         [-0.6908,  1.3018,  1.2799,  0.6820],\n",
       "         [ 0.5055,  0.4030,  0.8612,  1.3862]]]),\n",
       "indices=tensor([[[0, 0, 0, 0],\n",
       "         [1, 0, 2, 2],\n",
       "         [0, 1, 2, 2],\n",
       "         [2, 1, 1, 0]],\n",
       "\n",
       "        [[1, 2, 2, 0],\n",
       "         [1, 1, 2, 1],\n",
       "         [0, 0, 2, 0],\n",
       "         [0, 2, 0, 0]]]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(t, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988f3254",
   "metadata": {},
   "source": [
    "### Gradients in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dccb8001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(917., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[5., 8.],[4., 6.]], requires_grad=True)\n",
    "#store gradient after any operations\n",
    "y = x.pow(3).sum() #operation\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d1eeed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 75., 192.],\n",
       "        [ 48., 108.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward() #compute gradient\n",
    "x.grad  #print the gradient (it is stored in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ece9dcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 75., 192.],\n",
       "        [ 48., 108.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the result analitically\n",
    "3*x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a343f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
